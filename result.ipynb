{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from curses import tparm\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "from utils.util import get_mask_mnr, get_mask_bm, get_mask_rm\n",
    "from utils.util import find_max_epoch, print_size, sampling, calc_diffusion_hyperparams\n",
    "\n",
    "from imputers.DiffWaveImputer import DiffWaveImputer\n",
    "from imputers.SSSDSAImputer import SSSDSAImputer\n",
    "from imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,roc_curve, auc\n",
    "from statistics import mean\n",
    "# from dtaidistance import dtw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 1234\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation= np.load(\"results/ptbxl_248/no_trans/T200_beta00.0001_betaT0.02/imputation199.npy\")\n",
    "data=np.load(\"results/ptbxl_248/no_trans/T200_beta00.0001_betaT0.02/original11.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, samples, alarm, rule_based_results, groundtruth = torch.load(\n",
    "    'datasets/standardized_samples_alarms_results_embedding_labels.pt')\n",
    "# mu, sigma, samples, alarm, rule_based_results, groundtruth = torch.load(\n",
    "#     'datasets/2015_phy_stanardized.pt')\n",
    "# samples, alarm, groundtruth,records = torch.load(\n",
    "#     'datasets/samples.pt')\n",
    "\n",
    "VT_index,VT_True_index,VT_False_index=[],[],[]\n",
    "VT_index=[]\n",
    "VT_F_index=[]\n",
    "VFIB_index,VFIB_F_index=[],[]\n",
    "for i in range(len(samples)):\n",
    "    if alarm[i][0]==1:\n",
    "        VT_index.append(i)\n",
    "    if alarm[i][0]==1 and groundtruth[i]==0:\n",
    "        VT_F_index.append(i)  \n",
    "    if alarm[i][1]==1 and groundtruth[i]==1:\n",
    "        VFIB_index.append(i)\n",
    "    if alarm[i][1]==1 and groundtruth[i]==0:\n",
    "        VFIB_F_index.append(i)\n",
    "\n",
    "VT=True\n",
    "VFIB=False\n",
    "if VT==True:\n",
    "    VT_samples_valid=samples[VT_index][-1000:-670]\n",
    "    VT_samples_test=samples[VT_index][-670:]\n",
    "\n",
    "    test_gt=groundtruth[VT_index][-670:]\n",
    "    vaild_gt=groundtruth[VT_index][-1000:-670]\n",
    "if VFIB==True:\n",
    "    VFIB_samples_valid=samples[VFIB_index][-150:-100]\n",
    "    VFIB_samples_test=samples[VFIB_index][-100:]\n",
    "\n",
    "    test_gt=groundtruth[VFIB_index][-100:]\n",
    "    vaild_gt=groundtruth[VFIB_index][-150:-100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.zeros(data.shape)\n",
    "mask[:,:,250:] = 1\n",
    "mask=~mask.bool()\n",
    "mask=mask.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.from_numpy(data)\n",
    "result=torch.from_numpy(imputation[1:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    return (a-a.mean())/(a.max()-a.min()+0.00001)\n",
    "for i in range(12):\n",
    "    for j in range(result.shape[0]):\n",
    "        result[j,i,:]=normalize(result[j,i,:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=[]\n",
    "for i in range(data.shape[0]):\n",
    "    dist=F.mse_loss(result[i,:,:]*mask[i,:,:],data[i,:,:]*mask[i,:,:])\n",
    "    dists.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if VT==True:\n",
    "    vaild_dists=np.array(dists)[-1000:-670]\n",
    "    test_dists=np.array(dists)[-670:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best score in val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr,tfr,ths=roc_curve(vaild_gt,vaild_dists)\n",
    "Score=[0]\n",
    "Max_THRESHOLD={}\n",
    "\n",
    "for t in ths:\n",
    "    THRESHOLD = t # Anomaly score threshold for an instance to be considered as anomaly \n",
    "\n",
    "    #TIME_STEPS = dataset.window_length\n",
    "    test_score_df = pd.DataFrame(index=range(vaild_gt.shape[0]))\n",
    "    test_score_df['loss'] = vaild_dists\n",
    "    test_score_df['y'] = vaild_gt.numpy()\n",
    "    test_score_df['threshold'] = THRESHOLD\n",
    "    test_score_df['anomaly'] = test_score_df.loss <= test_score_df.threshold\n",
    "\n",
    "\n",
    "    start_end = []\n",
    "    state = 0\n",
    "    for idx in test_score_df.index:\n",
    "        if state==0 and test_score_df.loc[idx, 'y']==1:\n",
    "            state=1\n",
    "            start = idx\n",
    "        if state==1 and test_score_df.loc[idx, 'y']==0:\n",
    "            state = 0\n",
    "            end = idx\n",
    "            start_end.append((start, end))\n",
    "\n",
    "    for s_e in start_end:\n",
    "        if sum(test_score_df[s_e[0]:s_e[1]+1]['anomaly'])>0:\n",
    "            for i in range(s_e[0], s_e[1]+1):\n",
    "                test_score_df.loc[i, 'anomaly'] = 1\n",
    "    # test_score_df.to_csv(\"test.csv\")\n",
    "    actual = np.array(test_score_df['y'])\n",
    "    predicted = np.array([int(a) for a in test_score_df['anomaly']])\n",
    "\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    tp = np.count_nonzero(predicted * actual)\n",
    "    tn = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    fp = np.count_nonzero(predicted * (actual - 1))\n",
    "    fn = np.count_nonzero((predicted - 1) * actual)\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    score=(tp+tn)/(tp+tn+fp+5*fn)\n",
    "    if score>= max(Score):\n",
    "        Score.append(score)\n",
    "        Max_THRESHOLD.clear()\n",
    "        Max_THRESHOLD[\"thershold\"]=t\n",
    "        Max_THRESHOLD[\"TP\"]=tp\n",
    "        Max_THRESHOLD[\"TN\"]=tn\n",
    "        Max_THRESHOLD[\"FP\"]=fp\n",
    "        Max_THRESHOLD[\"FN\"]=fn\n",
    "        Max_THRESHOLD[\"accuracy\"]=accuracy\n",
    "        Max_THRESHOLD[\"score\"]=score\n",
    "        Max_THRESHOLD[\"TPR\"]=tp/(tp+fn)\n",
    "        Max_THRESHOLD[\"TNR\"]=tn/(tn+fp+0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thre=Max_THRESHOLD[\"thershold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr,tfr,ths=roc_curve(test_gt,test_dists)\n",
    "Score=[0]\n",
    "Max_THRESHOLD={}\n",
    "\n",
    "# for t in ths:\n",
    "THRESHOLD =thre# Anomaly score threshold for an instance to be considered as anomaly \n",
    "\n",
    "#TIME_STEPS = dataset.window_length\n",
    "test_score_df = pd.DataFrame(index=range(test_gt.shape[0]))\n",
    "test_score_df['loss'] = test_dists\n",
    "test_score_df['y'] = test_gt.numpy()\n",
    "test_score_df['threshold'] = THRESHOLD\n",
    "test_score_df['anomaly'] = test_score_df.loss <= test_score_df.threshold\n",
    "# test_score_df['t'] = [x[59].item() for x in test_dataset.x]\n",
    "\n",
    "# aUC=roc_auc_score(test_score_df['y'] ,test_score_df['anomaly'])\n",
    "\n",
    "start_end = []\n",
    "state = 0\n",
    "for idx in test_score_df.index:\n",
    "    if state==0 and test_score_df.loc[idx, 'y']==1:\n",
    "        state=1\n",
    "        start = idx\n",
    "    if state==1 and test_score_df.loc[idx, 'y']==0:\n",
    "        state = 0\n",
    "        end = idx\n",
    "        start_end.append((start, end))\n",
    "\n",
    "for s_e in start_end:\n",
    "    if sum(test_score_df[s_e[0]:s_e[1]+1]['anomaly'])>0:\n",
    "        for i in range(s_e[0], s_e[1]+1):\n",
    "            test_score_df.loc[i, 'anomaly'] = 1\n",
    "# test_score_df.to_csv(\"test.csv\")\n",
    "actual = np.array(test_score_df['y'])\n",
    "predicted = np.array([int(a) for a in test_score_df['anomaly']])\n",
    "\n",
    "predicted = np.array(predicted)\n",
    "actual = np.array(actual)\n",
    "\n",
    "tp = np.count_nonzero(predicted * actual)\n",
    "tn = np.count_nonzero((predicted - 1) * (actual - 1))\n",
    "fp = np.count_nonzero(predicted * (actual - 1))\n",
    "fn = np.count_nonzero((predicted - 1) * actual)\n",
    "accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "score=(tp+tn)/(tp+tn+fp+5*fn)\n",
    "# if score>= max(Score):\n",
    "#     Score.append(score)\n",
    "Max_THRESHOLD.clear()\n",
    "Max_THRESHOLD[\"thershold\"]=THRESHOLD\n",
    "Max_THRESHOLD[\"TP\"]=tp\n",
    "Max_THRESHOLD[\"TN\"]=tn\n",
    "Max_THRESHOLD[\"FP\"]=fp\n",
    "Max_THRESHOLD[\"FN\"]=fn\n",
    "Max_THRESHOLD[\"accuracy\"]=accuracy\n",
    "Max_THRESHOLD[\"score\"]=score\n",
    "Max_THRESHOLD[\"TPR\"]=tp/(tp+fn)\n",
    "Max_THRESHOLD[\"TNR\"]=tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=2\n",
    "cols=2\n",
    "j=12\n",
    "plt.figure(figsize=(12, 9))\n",
    "for i in range(1,5,1):\n",
    "    plt.subplot(rows,cols,i)\n",
    "    plt.plot(range(500),result[j+i,8,:],label=\"gen\")\n",
    "    plt.plot(range(500),data[j+i,8,:],label=\"Target\")\n",
    "    plt.legend()\n",
    "    # plt.title((\"Flase\" if test_gt[j+i]==0 else \"True\")+str(test_score_df['anomaly'][j+i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_score_df.index, test_score_df.loss, label='loss')\n",
    "# plt.plot(test_score_df.index, test_score_df.threshold, label='threshold')\n",
    "plt.axhline(Max_THRESHOLD[\"thershold\"], label='threshold',color='r')\n",
    "plt.plot(test_score_df.index, test_gt.numpy(), label='y')\n",
    "plt.xticks(rotation=25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(500),result[i,1,:],label=\"Gen\")\n",
    "    plt.plot(range(500),data[i,1,:],label=\"Target\")\n",
    "    plt.legend()\n",
    "    plt.title((\"GT: Flase II\" if test_gt[i]==0 else \"GT: True II\")+\"  Label:\"+str(test_score_df['anomaly'][i]))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(range(500),result[i,8,:],label=\"Gen\")\n",
    "    plt.plot(range(500),data[i,8,:],label=\"Target\")\n",
    "    plt.legend()\n",
    "    plt.title((\"GT: Flase ABP\" if test_gt[i]==0 else \"GT: True ABP\")+\"  Label:\"+str(test_score_df['anomaly'][i]))\n",
    "    plt.savefig(\"sample/\"+str(i)+\".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['I', 'II', 'III', 'V', 'aVF', 'aVL', 'aVR', 'PLETH','ABP','PAP','CVP','RESP']\n",
    "records_name=np.array(records)[VT_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 100):\n",
    "    plt.figure(figsize=(12, 18))\n",
    "    for j in range(12):\n",
    "        plt.subplot(6, 2, j+1)\n",
    "        plt.plot(range(500), result[i, j, :], label=\"Gen\")\n",
    "        plt.plot(range(500), data[i, j, :], label=\"Target\")\n",
    "        plt.text(250,0.45,\"observation part\")\n",
    "        plt.text(400,0.45,\"prediction part\")\n",
    "        plt.axvline(375,color='r',linestyle='--')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.title(records_name[i-1]+\"  \"+(\"GT: False  \"+name[j] if test_gt[i] == 0 else \"GT: True  \" +name[j]) +\n",
    "                    \"  Label:\" + str(bool(test_score_df['anomaly'][i])))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"sample/\" + str(i) + \".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
